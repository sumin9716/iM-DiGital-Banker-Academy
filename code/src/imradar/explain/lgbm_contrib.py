from __future__ import annotations

from typing import List, Tuple, Optional, Dict
import numpy as np
import pandas as pd

from imradar.models.forecast_lgbm import ForecastModel, predict_with_model


# ============== SHAP ê¸°ë°˜ í”¼ì²˜ ê¸°ì—¬ë„ ë¶„ì„ ==============

def local_feature_contrib(
    fm: ForecastModel,
    row_df: pd.DataFrame,
    top_k: int = 8,
) -> pd.DataFrame:
    """
    Compute local feature contributions using LightGBM's pred_contrib=True.
    Returns top positive/negative contributors for the given row (single-row dataframe).
    
    Args:
        fm: ForecastModel instance
        row_df: Single-row DataFrame
        top_k: Number of top contributors to return
    
    Returns:
        DataFrame with feature contributions
    """
    if row_df.shape[0] != 1:
        raise ValueError("row_df must have exactly 1 row")
    X = row_df[fm.feature_cols].copy()
    for c in fm.categorical_cols:
        if c in X.columns:
            X[c] = X[c].astype("category")

    contrib = fm.model.predict(X, pred_contrib=True)
    # contrib shape: (n, n_features+1) last column is bias
    contrib = contrib[0]
    feature_names = fm.feature_cols + ["bias"]
    s = pd.Series(contrib, index=feature_names).drop("bias")

    top_pos = s.sort_values(ascending=False).head(top_k // 2)
    top_neg = s.sort_values(ascending=True).head(top_k // 2)

    out = pd.concat([top_pos, top_neg]).reset_index()
    out.columns = ["feature", "contribution"]
    out["direction"] = np.where(out["contribution"] >= 0, "POS", "NEG")
    out["abs_contribution"] = out["contribution"].abs()
    out = out.sort_values("abs_contribution", ascending=False).reset_index(drop=True)
    return out


def compute_shap_values(
    fm: ForecastModel,
    df: pd.DataFrame,
    use_tree_shap: bool = True,
) -> np.ndarray:
    """
    SHAP ê°’ ê³„ì‚° (LightGBM Tree SHAP ë˜ëŠ” pred_contrib)
    
    Args:
        fm: ForecastModel instance
        df: Input DataFrame
        use_tree_shap: Trueë©´ SHAP ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©, Falseë©´ pred_contrib ì‚¬ìš©
    
    Returns:
        SHAP values array (n_samples, n_features)
    """
    X = df[fm.feature_cols].copy()
    for c in fm.categorical_cols:
        if c in X.columns:
            X[c] = X[c].astype("category")
    
    if use_tree_shap:
        try:
            import shap
            explainer = shap.TreeExplainer(fm.model)
            shap_values = explainer.shap_values(X)
            return shap_values
        except ImportError:
            print("SHAP ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. pred_contrib ì‚¬ìš©.")
    
    # Fallback to pred_contrib
    contribs = fm.model.predict(X, pred_contrib=True)
    return contribs[:, :-1]  # bias ì œì™¸


def batch_feature_contrib(
    fm: ForecastModel,
    df: pd.DataFrame,
    top_k: int = 5,
) -> pd.DataFrame:
    """
    ë°°ì¹˜ë¡œ ëª¨ë“  í–‰ì— ëŒ€í•´ feature contribution ê³„ì‚°
    
    Args:
        fm: ForecastModel instance
        df: Input DataFrame
        top_k: ê° í–‰ë‹¹ ë°˜í™˜í•  top contributor ìˆ˜
    
    Returns:
        DataFrame with segment, month, top features, contributions
    """
    X = df[fm.feature_cols].copy()
    for c in fm.categorical_cols:
        if c in X.columns:
            X[c] = X[c].astype("category")
    
    contribs = fm.model.predict(X, pred_contrib=True)
    # Remove bias column
    contribs = contribs[:, :-1]
    
    results = []
    for i, row_contrib in enumerate(contribs):
        s = pd.Series(row_contrib, index=fm.feature_cols)
        top_feats = s.abs().nlargest(top_k).index.tolist()
        
        row_result = {
            "row_idx": i,
            "top_features": top_feats,
            "contributions": [float(s[f]) for f in top_feats],
        }
        
        # ê°œë³„ í”¼ì²˜ ì»¬ëŸ¼ ì¶”ê°€
        for j, feat in enumerate(top_feats):
            row_result[f"feature_{j+1}"] = feat
            row_result[f"contrib_{j+1}"] = float(s[feat])
        
        results.append(row_result)
    
    return pd.DataFrame(results)


def global_feature_importance(
    fm: ForecastModel,
    importance_type: str = "gain",
) -> pd.DataFrame:
    """
    ê¸€ë¡œë²Œ í”¼ì²˜ ì¤‘ìš”ë„ ì¶”ì¶œ
    
    Args:
        fm: ForecastModel instance
        importance_type: "gain" ë˜ëŠ” "split"
    
    Returns:
        DataFrame with feature importance
    """
    if fm.feature_importance is not None:
        return fm.feature_importance.copy()
    
    # ì§ì ‘ ê³„ì‚°
    imp = fm.model.booster_.feature_importance(importance_type=importance_type)
    df = pd.DataFrame({
        'feature': fm.feature_cols,
        'importance': imp,
    })
    df['importance_pct'] = df['importance'] / df['importance'].sum() * 100
    return df.sort_values('importance', ascending=False).reset_index(drop=True)


def get_feature_groups(features: List[str]) -> Dict[str, List[str]]:
    """
    í”¼ì²˜ë¥¼ ê·¸ë£¹ë³„ë¡œ ë¶„ë¥˜
    
    Args:
        features: í”¼ì²˜ëª… ë¦¬ìŠ¤íŠ¸
    
    Returns:
        ê·¸ë£¹ë³„ í”¼ì²˜ ë”•ì…”ë„ˆë¦¬
    """
    groups = {
        "lag_features": [],
        "rolling_features": [],
        "ewm_features": [],
        "momentum_features": [],
        "zscore_features": [],
        "time_features": [],
        "categorical_features": [],
        "base_features": [],
    }
    
    for f in features:
        if "__lag" in f:
            groups["lag_features"].append(f)
        elif "__roll" in f:
            groups["rolling_features"].append(f)
        elif "__ewm" in f:
            groups["ewm_features"].append(f)
        elif "__mom" in f or "__yoy" in f or "__momentum" in f or "__accel" in f:
            groups["momentum_features"].append(f)
        elif "__zscore" in f:
            groups["zscore_features"].append(f)
        elif f in ["month_num", "quarter", "year", "month_sin", "month_cos", 
                   "quarter_sin", "quarter_cos", "is_quarter_end", "is_year_end"]:
            groups["time_features"].append(f)
        elif f.endswith("_cat") or f.endswith("_enc"):
            groups["categorical_features"].append(f)
        else:
            groups["base_features"].append(f)
    
    return {k: v for k, v in groups.items() if v}  # ë¹ˆ ê·¸ë£¹ ì œì™¸


def group_importance_summary(
    fm: ForecastModel,
    importance_type: str = "gain",
) -> pd.DataFrame:
    """
    í”¼ì²˜ ê·¸ë£¹ë³„ ì¤‘ìš”ë„ ìš”ì•½
    
    Args:
        fm: ForecastModel instance
        importance_type: "gain" ë˜ëŠ” "split"
    
    Returns:
        ê·¸ë£¹ë³„ ì¤‘ìš”ë„ ìš”ì•½ DataFrame
    """
    imp_df = global_feature_importance(fm, importance_type)
    feature_groups = get_feature_groups(fm.feature_cols)
    
    results = []
    for group_name, group_features in feature_groups.items():
        group_imp = imp_df[imp_df['feature'].isin(group_features)]
        if len(group_imp) > 0:
            results.append({
                "group": group_name,
                "feature_count": len(group_features),
                "total_importance": float(group_imp['importance'].sum()),
                "avg_importance": float(group_imp['importance'].mean()),
                "top_feature": group_imp.iloc[0]['feature'] if len(group_imp) > 0 else "",
            })
    
    result_df = pd.DataFrame(results)
    result_df["importance_pct"] = result_df["total_importance"] / result_df["total_importance"].sum() * 100
    return result_df.sort_values("total_importance", ascending=False).reset_index(drop=True)


def driver_sentence(contrib_df: pd.DataFrame, max_terms: int = 3) -> str:
    """
    Convert contribution list to a concise Korean driver sentence.
    
    Args:
        contrib_df: Contribution DataFrame
        max_terms: Maximum number of terms to include
    
    Returns:
        Korean driver explanation sentence
    """
    pos = contrib_df[contrib_df["direction"] == "POS"].sort_values("contribution", ascending=False).head(max_terms)
    neg = contrib_df[contrib_df["direction"] == "NEG"].sort_values("contribution", ascending=True).head(max_terms)

    def _fmt(df: pd.DataFrame) -> str:
        feats = df["feature"].tolist()
        if not feats:
            return ""
        # shorten names
        feats = [_format_feature_name(f) for f in feats]
        return ", ".join(feats)

    pos_txt = _fmt(pos)
    neg_txt = _fmt(neg)

    if pos_txt and neg_txt:
        return f"ìƒìŠ¹ ìš”ì¸: {pos_txt} / í•˜ë½ ìš”ì¸: {neg_txt}"
    if pos_txt:
        return f"ìƒìŠ¹ ìš”ì¸: {pos_txt}"
    if neg_txt:
        return f"í•˜ë½ ìš”ì¸: {neg_txt}"
    return "ì£¼ìš” ë“œë¼ì´ë²„ê°€ ëšœë ·í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."


def _format_feature_name(feature: str) -> str:
    """
    í”¼ì²˜ëª…ì„ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë³€í™˜
    
    Args:
        feature: ì›ë³¸ í”¼ì²˜ëª…
    
    Returns:
        í¬ë§·ëœ í”¼ì²˜ëª…
    """
    # ì ‘ë‘ì‚¬ ì œê±°
    name = feature.replace("log1p_", "").replace("__", ":")
    
    # íŠ¹ìˆ˜ ë³€í™˜
    replacements = {
        ":lag1": "(1ê°œì›”ì „)",
        ":lag2": "(2ê°œì›”ì „)",
        ":lag3": "(3ê°œì›”ì „)",
        ":lag6": "(6ê°œì›”ì „)",
        ":lag12": "(12ê°œì›”ì „)",
        ":roll3_mean": "(3ê°œì›”í‰ê· )",
        ":roll6_mean": "(6ê°œì›”í‰ê· )",
        ":roll3_std": "(3ê°œì›”ë³€ë™)",
        ":roll6_std": "(6ê°œì›”ë³€ë™)",
        ":ewm3": "(ë‹¨ê¸°ì¶”ì„¸)",
        ":ewm6": "(ì¤‘ê¸°ì¶”ì„¸)",
        ":ewm12": "(ì¥ê¸°ì¶”ì„¸)",
        ":mom": "(MoM)",
        ":yoy": "(YoY)",
        ":3m_change": "(3ê°œì›”ë³€í™”)",
        ":accel": "(ê°€ì†ë„)",
        ":zscore12": "(ì´ìƒë„)",
        ":momentum_3_12": "(ëª¨ë©˜í…€)",
    }
    
    for old, new in replacements.items():
        name = name.replace(old, new)
    
    return name


def generate_alert_explanation(
    fm: ForecastModel,
    alert_row: pd.DataFrame,
    include_recommendation: bool = True,
) -> Dict[str, any]:
    """
    ì•Œë¦¼ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª… ìƒì„±
    
    Args:
        fm: ForecastModel instance
        alert_row: ì•Œë¦¼ ë°ì´í„° (ë‹¨ì¼ í–‰)
        include_recommendation: ê¶Œê³ ì‚¬í•­ í¬í•¨ ì—¬ë¶€
    
    Returns:
        ì„¤ëª… ë”•ì…”ë„ˆë¦¬
    """
    contrib = local_feature_contrib(fm, alert_row, top_k=8)
    
    explanation = {
        "driver_summary": driver_sentence(contrib),
        "top_positive_drivers": contrib[contrib["direction"] == "POS"]["feature"].tolist()[:3],
        "top_negative_drivers": contrib[contrib["direction"] == "NEG"]["feature"].tolist()[:3],
        "contributions": contrib.to_dict('records'),
    }
    
    if include_recommendation:
        # ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ê¶Œê³ ì‚¬í•­
        pos_features = explanation["top_positive_drivers"]
        neg_features = explanation["top_negative_drivers"]
        
        recommendations = []
        
        for feat in neg_features:
            if "ì˜ˆê¸ˆ" in feat or "deposit" in feat.lower():
                recommendations.append("ì˜ˆê¸ˆ ì´íƒˆ ë°©ì§€ë¥¼ ìœ„í•œ ê³ ê° ì»¨íƒ í•„ìš”")
            elif "ëŒ€ì¶œ" in feat or "loan" in feat.lower():
                recommendations.append("ëŒ€ì¶œ ìƒí™˜ ë™í–¥ ëª¨ë‹ˆí„°ë§ í•„ìš”")
            elif "ì¹´ë“œ" in feat or "card" in feat.lower():
                recommendations.append("ì¹´ë“œ í™œì„±í™” ìº í˜ì¸ ê²€í† ")
            elif "ë””ì§€í„¸" in feat or "digital" in feat.lower():
                recommendations.append("ë””ì§€í„¸ ì±„ë„ ì´ìš© ì´‰ì§„ í•„ìš”")
        
        explanation["recommendations"] = recommendations if recommendations else ["ìƒì„¸ ë¶„ì„ í•„ìš”"]
    
    return explanation


# ============== í™•ì¥ëœ SHAP ë¶„ì„ ê¸°ëŠ¥ ==============

def generate_segment_explanation(
    fm: ForecastModel,
    segment_df: pd.DataFrame,
    segment_id: str,
    target_month: pd.Timestamp,
    top_k: int = 5,
) -> Dict[str, any]:
    """
    íŠ¹ì • ì„¸ê·¸ë¨¼íŠ¸-ì›”ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª… ìƒì„±
    
    Args:
        fm: ForecastModel
        segment_df: í•´ë‹¹ ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„°
        segment_id: ì„¸ê·¸ë¨¼íŠ¸ ID
        target_month: ë¶„ì„ ëŒ€ìƒ ì›”
        top_k: ìƒìœ„ ë“œë¼ì´ë²„ ìˆ˜
    
    Returns:
        ì„¤ëª… ë”•ì…”ë„ˆë¦¬
    """
    # í•´ë‹¹ ì„¸ê·¸ë¨¼íŠ¸-ì›” ë°ì´í„° ì¶”ì¶œ
    mask = (segment_df["segment_id"] == segment_id) & (segment_df["month"] == target_month)
    row = segment_df[mask]
    
    if row.empty:
        return {"error": "í•´ë‹¹ ì„¸ê·¸ë¨¼íŠ¸-ì›” ë°ì´í„° ì—†ìŒ"}
    
    row_df = row.iloc[[0]]
    
    # ê¸°ì—¬ë„ ê³„ì‚°
    contrib = local_feature_contrib(fm, row_df, top_k=top_k * 2)
    
    # í”¼ì²˜ë³„ ê·¸ë£¹í™”
    internal_drivers = []
    external_drivers = []
    
    external_keywords = ["ESI", "fed", "usd", "wti", "brent", "export", "import", 
                        "call_rate", "koribor", "cpi", "ppi", "retail", "employment"]
    
    for _, r in contrib.iterrows():
        feat = r["feature"]
        is_external = any(kw in feat.lower() for kw in external_keywords)
        
        driver_info = {
            "feature": feat,
            "display_name": _format_feature_name(feat),
            "contribution": float(r["contribution"]),
            "direction": r["direction"],
        }
        
        if is_external:
            external_drivers.append(driver_info)
        else:
            internal_drivers.append(driver_info)
    
    # ì„¤ëª… ë¬¸ì¥ ìƒì„±
    explanation_parts = []
    
    if internal_drivers:
        top_internal = sorted(internal_drivers, key=lambda x: abs(x["contribution"]), reverse=True)[:3]
        internal_names = [d["display_name"] for d in top_internal]
        explanation_parts.append(f"ë‚´ë¶€ ìš”ì¸: {', '.join(internal_names)}")
    
    if external_drivers:
        top_external = sorted(external_drivers, key=lambda x: abs(x["contribution"]), reverse=True)[:3]
        external_names = [d["display_name"] for d in top_external]
        explanation_parts.append(f"ì™¸ë¶€ ìš”ì¸: {', '.join(external_names)}")
    
    return {
        "segment_id": segment_id,
        "month": str(target_month),
        "internal_drivers": internal_drivers[:top_k],
        "external_drivers": external_drivers[:top_k],
        "explanation": " / ".join(explanation_parts) if explanation_parts else "ì£¼ìš” ë“œë¼ì´ë²„ ë¯¸í™•ì¸",
        "all_contributions": contrib.to_dict("records"),
    }


def generate_narrative_report(
    fm: ForecastModel,
    df: pd.DataFrame,
    segment_id: str,
    target_month: pd.Timestamp,
    actual: float,
    predicted: float,
) -> str:
    """
    ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ í˜•íƒœì˜ ì„œìˆ í˜• ë¦¬í¬íŠ¸ ìƒì„±
    
    Args:
        fm: ForecastModel
        df: ë¶„ì„ ë°ì´í„°
        segment_id: ì„¸ê·¸ë¨¼íŠ¸ ID
        target_month: ë¶„ì„ ì›”
        actual: ì‹¤ì œê°’
        predicted: ì˜ˆì¸¡ê°’
    
    Returns:
        ì„œìˆ í˜• ë¦¬í¬íŠ¸ ë¬¸ìì—´
    """
    # ê¸°ì—¬ë„ ë¶„ì„
    explanation = generate_segment_explanation(fm, df, segment_id, target_month)
    
    if "error" in explanation:
        return f"ë¶„ì„ ì˜¤ë¥˜: {explanation['error']}"
    
    # ì”ì°¨ ê³„ì‚°
    residual = actual - predicted
    residual_ratio = residual / (abs(predicted) + 1e-9) * 100
    direction = "ìƒìŠ¹" if residual > 0 else "í•˜ë½"
    
    # ë¦¬í¬íŠ¸ ì‘ì„±
    report_lines = [
        f"=== ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„ ë¦¬í¬íŠ¸ ===",
        f"",
        f"â–  ì„¸ê·¸ë¨¼íŠ¸: {segment_id}",
        f"â–  ë¶„ì„ ì›”: {target_month.strftime('%Yë…„ %mì›”')}",
        f"",
        f"â–  ì„±ê³¼ ìš”ì•½",
        f"  - ì‹¤ì : {actual:,.0f}",
        f"  - ì˜ˆì¸¡: {predicted:,.0f}",
        f"  - ì°¨ì´: {residual:+,.0f} ({residual_ratio:+.1f}%)",
        f"  - ë°©í–¥: ì˜ˆì¸¡ ëŒ€ë¹„ {direction}",
        f"",
        f"â–  ì£¼ìš” ì›ì¸ ë¶„ì„",
    ]
    
    # ë‚´ë¶€ ìš”ì¸
    if explanation.get("internal_drivers"):
        report_lines.append(f"  [ë‚´ë¶€ ìš”ì¸]")
        for i, d in enumerate(explanation["internal_drivers"][:3], 1):
            direction_txt = "+" if d["contribution"] > 0 else "-"
            report_lines.append(f"    {i}. {d['display_name']} ({direction_txt}{abs(d['contribution']):.2f})")
    
    # ì™¸ë¶€ ìš”ì¸
    if explanation.get("external_drivers"):
        report_lines.append(f"  [ì™¸ë¶€ ìš”ì¸]")
        for i, d in enumerate(explanation["external_drivers"][:3], 1):
            direction_txt = "+" if d["contribution"] > 0 else "-"
            report_lines.append(f"    {i}. {d['display_name']} ({direction_txt}{abs(d['contribution']):.2f})")
    
    # ê¶Œê³ ì‚¬í•­
    report_lines.append(f"")
    report_lines.append(f"â–  ê¶Œê³ ì‚¬í•­")
    
    recommendations = _generate_recommendations(explanation, residual_ratio)
    for i, rec in enumerate(recommendations[:3], 1):
        report_lines.append(f"  {i}. {rec}")
    
    return "\n".join(report_lines)


def _generate_recommendations(
    explanation: Dict[str, any],
    residual_ratio: float,
) -> List[str]:
    """
    ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ê¶Œê³ ì‚¬í•­ ìƒì„±
    
    Args:
        explanation: ì„¤ëª… ë”•ì…”ë„ˆë¦¬
        residual_ratio: ì”ì°¨ ë¹„ìœ¨ (%)
    
    Returns:
        ê¶Œê³ ì‚¬í•­ ë¦¬ìŠ¤íŠ¸
    """
    recommendations = []
    
    # ì”ì°¨ ë°©í–¥ì— ë”°ë¥¸ ê¸°ë³¸ ê¶Œê³ 
    if residual_ratio < -20:
        recommendations.append("ì‹¤ì  ê¸‰ê° ì›ì¸ ê¸´ê¸‰ ë¶„ì„ ë° ëŒ€ì‘ í•„ìš”")
    elif residual_ratio < -10:
        recommendations.append("ì‹¤ì  í•˜ë½ ì¶”ì„¸ ëª¨ë‹ˆí„°ë§ ë° ì¡°ê¸° ëŒ€ì‘ ê²€í† ")
    elif residual_ratio > 20:
        recommendations.append("ì„±ê³¼ ìƒìŠ¹ ìš”ì¸ ë¶„ì„ ë° íƒ€ ì„¸ê·¸ë¨¼íŠ¸ í™•ì‚° ê²€í† ")
    elif residual_ratio > 10:
        recommendations.append("ê¸ì •ì  ì¶”ì„¸ ì§€ì† ì—¬ë¶€ ëª¨ë‹ˆí„°ë§")
    
    # ë“œë¼ì´ë²„ ê¸°ë°˜ ê¶Œê³ 
    all_drivers = (
        explanation.get("internal_drivers", []) + 
        explanation.get("external_drivers", [])
    )
    
    for driver in all_drivers[:5]:
        feat = driver["feature"].lower()
        contrib = driver["contribution"]
        
        # í•˜ë½ ì›ì¸ ë“œë¼ì´ë²„
        if contrib < 0:
            if "ì˜ˆê¸ˆ" in feat:
                recommendations.append("ì˜ˆê¸ˆ ì´íƒˆ ë°©ì§€ë¥¼ ìœ„í•œ ê³ ê¸ˆë¦¬ ìƒí’ˆ í”„ë¡œëª¨ì…˜ ê²€í† ")
            elif "ëŒ€ì¶œ" in feat:
                recommendations.append("ëŒ€ì¶œ ê³ ê° ì´íƒˆ ë°©ì§€ ë° ë¦¬í…ì…˜ í”„ë¡œê·¸ë¨ ê°•í™”")
            elif "ì¹´ë“œ" in feat:
                recommendations.append("ì¹´ë“œ ì‚¬ìš© í™œì„±í™” ìº í˜ì¸ ê¸°íš")
            elif "ë””ì§€í„¸" in feat:
                recommendations.append("ë””ì§€í„¸ ì±„ë„ ì´ìš© ì´‰ì§„ ë° ì˜¨ë³´ë”© ê°œì„ ")
            elif "fx" in feat or "ì™¸í™˜" in feat:
                recommendations.append("FX ê±°ë˜ í™œì„±í™” ë° í™˜ìœ¨ ë³€ë™ ë¦¬ìŠ¤í¬ í—¤ì§€ ìƒí’ˆ ì œì•ˆ")
            elif "usd" in feat or "í™˜ìœ¨" in feat:
                recommendations.append("í™˜ìœ¨ ë³€ë™ ì˜í–¥ ëª¨ë‹ˆí„°ë§ ë° ê³ ê° ì»¤ë®¤ë‹ˆì¼€ì´ì…˜")
            elif "ê¸ˆë¦¬" in feat or "rate" in feat:
                recommendations.append("ê¸ˆë¦¬ ë¯¼ê°ë„ ë¶„ì„ ë° ìƒí’ˆ í¬íŠ¸í´ë¦¬ì˜¤ ì¬ê²€í† ")
        
        # ìƒìŠ¹ ì›ì¸ ë“œë¼ì´ë²„
        else:
            if "ì˜ˆê¸ˆ" in feat:
                recommendations.append("ì˜ˆê¸ˆ ìœ ì¹˜ ì„±ê³µ ìš”ì¸ ë¶„ì„ ë° íƒ€ ì„¸ê·¸ë¨¼íŠ¸ ì ìš©")
            elif "ëŒ€ì¶œ" in feat:
                recommendations.append("ëŒ€ì¶œ ìˆ˜ìš” ì¦ê°€ ì¶”ì„¸ í™œìš©, êµì°¨íŒë§¤ ê¸°íšŒ íƒìƒ‰")
    
    # ì¤‘ë³µ ì œê±°
    seen = set()
    unique_recs = []
    for rec in recommendations:
        if rec not in seen:
            seen.add(rec)
            unique_recs.append(rec)
    
    return unique_recs if unique_recs else ["ìƒì„¸ ë¶„ì„ í•„ìš”"]


def generate_monthly_top_alerts_report(
    fm: ForecastModel,
    df: pd.DataFrame,
    target_month: pd.Timestamp,
    top_n: int = 10,
) -> str:
    """
    ì›”ê°„ TOP ê²½ë³´ ì„¸ê·¸ë¨¼íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±
    
    Args:
        fm: ForecastModel
        df: ë¶„ì„ ë°ì´í„° (ì˜ˆì¸¡ê°’, ì‹¤ì œê°’ í¬í•¨)
        target_month: ë¶„ì„ ì›”
        top_n: ìƒìœ„ ì•Œë¦¼ ìˆ˜
    
    Returns:
        ì¢…í•© ë¦¬í¬íŠ¸ ë¬¸ìì—´
    """
    # í•´ë‹¹ ì›” ë°ì´í„° í•„í„°ë§
    month_data = df[df["month"] == target_month].copy()
    
    if month_data.empty:
        return f"ë°ì´í„° ì—†ìŒ: {target_month}"
    
    # ì”ì°¨ ê³„ì‚° (ì˜ˆì¸¡ê°’, ì‹¤ì œê°’ì´ ìˆë‹¤ê³  ê°€ì •)
    if "predicted" not in month_data.columns:
        predictions = predict_with_model(fm, month_data)
        month_data["predicted"] = predictions
    
    if "actual" not in month_data.columns and fm.kpi in month_data.columns:
        month_data["actual"] = month_data[fm.kpi]
    
    eps = 1e-9
    month_data["residual"] = month_data["actual"] - month_data["predicted"]
    month_data["residual_ratio"] = month_data["residual"] / (month_data["predicted"].abs() + eps)
    
    # ìƒìœ„/í•˜ìœ„ ì•Œë¦¼ ì¶”ì¶œ
    top_drop = month_data.nsmallest(top_n // 2, "residual_ratio")
    top_surge = month_data.nlargest(top_n // 2, "residual_ratio")
    
    report_lines = [
        f"{'='*60}",
        f"ì›”ê°„ ì„¸ê·¸ë¨¼íŠ¸ ê²½ë³´ ë¦¬í¬íŠ¸",
        f"ë¶„ì„ ì›”: {target_month.strftime('%Yë…„ %mì›”')}",
        f"{'='*60}",
        f"",
        f"â–  ê¸‰ê° ì„¸ê·¸ë¨¼íŠ¸ TOP {len(top_drop)}",
        f"-" * 40,
    ]
    
    for idx, (_, row) in enumerate(top_drop.iterrows(), 1):
        segment_id = row.get("segment_id", "N/A")
        residual_pct = row["residual_ratio"] * 100
        
        # ê°„ë‹¨í•œ ë“œë¼ì´ë²„ ë¶„ì„
        try:
            row_df = pd.DataFrame([row])
            contrib = local_feature_contrib(fm, row_df[fm.feature_cols].copy(), top_k=4)
            top_drivers = [_format_feature_name(f) for f in contrib.head(3)["feature"]]
            driver_txt = ", ".join(top_drivers)
        except:
            driver_txt = "ë¶„ì„ ë¶ˆê°€"
        
        report_lines.append(f"{idx}. {segment_id}: {residual_pct:+.1f}%")
        report_lines.append(f"   ë“œë¼ì´ë²„: {driver_txt}")
        report_lines.append("")
    
    report_lines.append(f"")
    report_lines.append(f"â–  ê¸‰ì¦ ì„¸ê·¸ë¨¼íŠ¸ TOP {len(top_surge)}")
    report_lines.append(f"-" * 40)
    
    for idx, (_, row) in enumerate(top_surge.iterrows(), 1):
        segment_id = row.get("segment_id", "N/A")
        residual_pct = row["residual_ratio"] * 100
        
        try:
            row_df = pd.DataFrame([row])
            contrib = local_feature_contrib(fm, row_df[fm.feature_cols].copy(), top_k=4)
            top_drivers = [_format_feature_name(f) for f in contrib.head(3)["feature"]]
            driver_txt = ", ".join(top_drivers)
        except:
            driver_txt = "ë¶„ì„ ë¶ˆê°€"
        
        report_lines.append(f"{idx}. {segment_id}: {residual_pct:+.1f}%")
        report_lines.append(f"   ë“œë¼ì´ë²„: {driver_txt}")
        report_lines.append("")
    
    return "\n".join(report_lines)


# ============== ìì—°ì–´ ë¬¸ì¥í˜• ì„¤ëª… ìƒì„± ==============

# í”¼ì²˜-ì„¤ëª… ë§¤í•‘ ì‚¬ì „
FEATURE_DESCRIPTIONS = {
    # í™˜ìœ¨/FX ê´€ë ¨
    "usd_krw": "í™˜ìœ¨",
    "fx_level": "í™˜ìœ¨ ìˆ˜ì¤€",
    "fx_mom": "í™˜ìœ¨ ë³€ë™",
    "fx_vol": "í™˜ìœ¨ ë³€ë™ì„±",
    "fx_regime": "í™˜ìœ¨ êµ­ë©´",
    
    # ê¸ˆë¦¬ ê´€ë ¨
    "fed_rate": "ë¯¸êµ­ ê¸ˆë¦¬",
    "call_rate": "ì½œê¸ˆë¦¬",
    "koribor": "KORIBOR",
    "govt_bond": "êµ­ê³ ì±„ ê¸ˆë¦¬",
    "corp_bond": "íšŒì‚¬ì±„ ê¸ˆë¦¬",
    
    # ìœ ê°€/ì›ìì¬
    "wti": "ìœ ê°€(WTI)",
    "brent": "ìœ ê°€(Brent)",
    "oil": "ìœ ê°€",
    
    # ê²½ê¸° ì§€í‘œ
    "esi": "ê²½ê¸°ì‹¬ë¦¬ì§€ìˆ˜(ESI)",
    "kasi": "ê¸°ì—…ê²½ê¸°ì‹¬ë¦¬ì§€ìˆ˜",
    "cpi": "ì†Œë¹„ìë¬¼ê°€",
    "ppi": "ìƒì‚°ìë¬¼ê°€",
    
    # ë¬´ì—­
    "export": "ìˆ˜ì¶œ",
    "import": "ìˆ˜ì…",
    "trade_balance": "ë¬´ì—­ìˆ˜ì§€",
    
    # ë¶€ë™ì‚°
    "housing_price": "ì£¼íƒê°€ê²©",
    "jeonse_price": "ì „ì„¸ê°€ê²©",
    "apt_transaction": "ì•„íŒŒíŠ¸ ê±°ë˜ëŸ‰",
    "apt_vol": "ë¶€ë™ì‚° ê±°ë˜ëŸ‰",
    
    # KPI ê´€ë ¨
    "ì˜ˆê¸ˆì´ì”ì•¡": "ì˜ˆê¸ˆì”ì•¡",
    "ëŒ€ì¶œì´ì”ì•¡": "ëŒ€ì¶œì”ì•¡",
    "ì¹´ë“œì´ì‚¬ìš©": "ì¹´ë“œì‚¬ìš©ì•¡",
    "ë””ì§€í„¸ê±°ë˜ê¸ˆì•¡": "ë””ì§€í„¸ê±°ë˜",
    "ìˆœìœ ì…": "ìê¸ˆìˆœìœ ì…",
    "FXì´ì•¡": "ì™¸í™˜ê±°ë˜",
    "í•œë„ì†Œì§„ìœ¨": "ì—¬ì‹ í•œë„ ì‚¬ìš©ë¥ ",
    "ë””ì§€í„¸ë¹„ì¤‘": "ë””ì§€í„¸ ì±„ë„ ë¹„ì¤‘",
}

# ë³€í™” ìœ í˜•ë³„ ì„¤ëª…
CHANGE_TYPE_DESCRIPTIONS = {
    "lag": "ê³¼ê±° {period}ê°œì›” ì „ ê°’",
    "mom": "ì „ì›” ëŒ€ë¹„ ë³€í™”",
    "yoy": "ì „ë…„ ë™ì›” ëŒ€ë¹„ ë³€í™”",
    "roll_mean": "{window}ê°œì›” ì´ë™í‰ê· ",
    "roll_std": "{window}ê°œì›” ë³€ë™ì„±",
    "zscore": "ì´ìƒì¹˜ ìˆ˜ì¤€",
    "ma": "ì´ë™í‰ê· ",
    "vol": "ë³€ë™ì„±",
}


def parse_feature_name_v2(feature: str) -> Tuple[str, str, Optional[int]]:
    """
    í”¼ì²˜ëª… íŒŒì‹± (v2)
    
    Args:
        feature: í”¼ì²˜ëª… (ì˜ˆ: "usd_krw_mean__lag3", "FXì´ì•¡__mom_pct")
    
    Returns:
        (base_name, change_type, period)
    """
    import re
    
    parts = feature.split("__")
    base_name = parts[0]
    change_type = ""
    period = None
    
    if len(parts) > 1:
        suffix = parts[1]
        
        if suffix.startswith("lag"):
            change_type = "lag"
            try:
                period = int(suffix[3:])
            except:
                period = None
        elif "mom" in suffix:
            change_type = "mom"
        elif "yoy" in suffix:
            change_type = "yoy"
        elif "roll" in suffix and "mean" in suffix:
            change_type = "roll_mean"
            match = re.search(r'\d+', suffix)
            if match:
                period = int(match.group())
        elif "roll" in suffix and "std" in suffix:
            change_type = "roll_std"
            match = re.search(r'\d+', suffix)
            if match:
                period = int(match.group())
        elif "zscore" in suffix:
            change_type = "zscore"
        elif "ma" in suffix:
            change_type = "ma"
            match = re.search(r'\d+', suffix)
            if match:
                period = int(match.group())
    
    return base_name, change_type, period


def get_readable_feature_name(feature: str) -> str:
    """
    í”¼ì²˜ëª…ì„ ì½ê¸° ì‰¬ìš´ í•œêµ­ì–´ë¡œ ë³€í™˜
    
    Args:
        feature: í”¼ì²˜ëª…
    
    Returns:
        í•œêµ­ì–´ ì„¤ëª…
    """
    base_name, change_type, period = parse_feature_name_v2(feature)
    
    # ê¸°ë³¸ ì´ë¦„ ë³€í™˜
    readable_base = base_name
    for key, desc in FEATURE_DESCRIPTIONS.items():
        if key in base_name.lower():
            readable_base = desc
            break
    
    # ë³€í™” ìœ í˜• ì¶”ê°€
    if change_type == "lag" and period:
        return f"{readable_base} ({period}ê°œì›” ì „)"
    elif change_type == "mom":
        return f"{readable_base} (ì „ì›”ë¹„)"
    elif change_type == "yoy":
        return f"{readable_base} (ì „ë…„ë¹„)"
    elif change_type == "roll_mean" and period:
        return f"{readable_base} ({period}ê°œì›” í‰ê· )"
    elif change_type == "roll_std" and period:
        return f"{readable_base} ({period}ê°œì›” ë³€ë™ì„±)"
    elif change_type == "zscore":
        return f"{readable_base} (ì´ìƒë„)"
    elif change_type == "ma" and period:
        return f"{readable_base} ({period}ì¼ ì´ë™í‰ê· )"
    else:
        return readable_base


def generate_explanation_sentence(
    segment_id: str,
    kpi: str,
    direction: str,
    top_contributors: pd.DataFrame,
    magnitude: float = 0,
) -> str:
    """
    ë‹¨ì¼ ì„¸ê·¸ë¨¼íŠ¸ì— ëŒ€í•œ ìì—°ì–´ ì„¤ëª… ë¬¸ì¥ ìƒì„±
    
    Args:
        segment_id: ì„¸ê·¸ë¨¼íŠ¸ ID
        kpi: KPIëª…
        direction: ë³€í™” ë°©í–¥ ("increase", "decrease", "anomaly")
        top_contributors: ìƒìœ„ ê¸°ì—¬ í”¼ì²˜ DataFrame (feature, contribution ì»¬ëŸ¼)
        magnitude: ë³€í™” í¬ê¸° (%)
    
    Returns:
        ìì—°ì–´ ì„¤ëª… ë¬¸ì¥
    """
    # ë°©í–¥ í…ìŠ¤íŠ¸
    direction_text = {
        "increase": "ìƒìŠ¹",
        "decrease": "í•˜ë½",
        "anomaly": "ì´ìƒ ë³€ë™",
        "surge": "ê¸‰ì¦",
        "drop": "ê¸‰ê°",
    }.get(direction, "ë³€ë™")
    
    # ìƒìœ„ ê¸°ì—¬ ìš”ì¸ ì¶”ì¶œ
    positive_factors = []
    negative_factors = []
    
    for _, row in top_contributors.iterrows():
        feat_name = get_readable_feature_name(row["feature"])
        contrib = row["contribution"]
        
        if contrib > 0:
            positive_factors.append(feat_name)
        else:
            negative_factors.append(feat_name)
    
    # ë¬¸ì¥ êµ¬ì„±
    sentences = []
    
    # ë©”ì¸ ë¬¸ì¥
    if magnitude != 0:
        main_sentence = f"í•´ë‹¹ ì„¸ê·¸ë¨¼íŠ¸ì˜ {kpi}ì´(ê°€) ì˜ˆì¸¡ ëŒ€ë¹„ {abs(magnitude):.1f}% {direction_text}í•˜ì˜€ìŠµë‹ˆë‹¤."
    else:
        main_sentence = f"í•´ë‹¹ ì„¸ê·¸ë¨¼íŠ¸ì˜ {kpi}ì—ì„œ {direction_text}ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤."
    sentences.append(main_sentence)
    
    # ì›ì¸ ë¬¸ì¥
    if positive_factors:
        pos_text = ", ".join(positive_factors[:3])
        sentences.append(f"ì£¼ìš” ìƒìŠ¹ ìš”ì¸: {pos_text}")
    
    if negative_factors:
        neg_text = ", ".join(negative_factors[:3])
        sentences.append(f"ì£¼ìš” í•˜ë½ ìš”ì¸: {neg_text}")
    
    # ì™¸ë¶€ ìš”ì¸ ê°•ì¡°
    external_keywords = ["í™˜ìœ¨", "ê¸ˆë¦¬", "ìœ ê°€", "ë¬¼ê°€", "ìˆ˜ì¶œ", "ìˆ˜ì…", "ê²½ê¸°", "ë¶€ë™ì‚°"]
    external_factors = [f for f in (positive_factors + negative_factors) 
                        if any(kw in f for kw in external_keywords)]
    
    if external_factors:
        ext_text = ", ".join(external_factors[:2])
        sentences.append(f"â€» ì™¸ë¶€ ê±°ì‹œê²½ì œ ìš”ì¸({ext_text})ì˜ ì˜í–¥ì´ ê´€ì¸¡ë¨")
    
    return " ".join(sentences)


def generate_segment_explanation(
    fm: ForecastModel,
    row_df: pd.DataFrame,
    kpi: str,
    residual_pct: float,
    alert_type: str = "normal",
    top_k: int = 6,
) -> str:
    """
    ì„¸ê·¸ë¨¼íŠ¸ë³„ ìƒì„¸ ì„¤ëª… ìƒì„±
    
    Args:
        fm: ForecastModel instance
        row_df: ë‹¨ì¼ í–‰ DataFrame
        kpi: KPIëª…
        residual_pct: ì”ì°¨ ë¹„ìœ¨ (%)
        alert_type: ì•Œë¦¼ ìœ í˜•
        top_k: ìƒìœ„ ê¸°ì—¬ í”¼ì²˜ ìˆ˜
    
    Returns:
        ìì—°ì–´ ì„¤ëª… ë¬¸ì¥
    """
    try:
        # í”¼ì²˜ ê¸°ì—¬ë„ ê³„ì‚°
        contrib = local_feature_contrib(fm, row_df, top_k=top_k)
        
        # ë°©í–¥ ê²°ì •
        if residual_pct > 20:
            direction = "surge"
        elif residual_pct < -20:
            direction = "drop"
        elif residual_pct > 0:
            direction = "increase"
        elif residual_pct < 0:
            direction = "decrease"
        else:
            direction = "normal"
        
        segment_id = row_df.iloc[0].get("segment_id", "Unknown") if "segment_id" in row_df.columns else "Unknown"
        
        explanation = generate_explanation_sentence(
            segment_id=segment_id,
            kpi=kpi,
            direction=direction,
            top_contributors=contrib,
            magnitude=residual_pct,
        )
        
        return explanation
    
    except Exception as e:
        return f"ì„¤ëª… ìƒì„± ì‹¤íŒ¨: {e}"


def generate_batch_explanations(
    fm: ForecastModel,
    df: pd.DataFrame,
    kpi: str,
    residual_col: str = "residual_pct",
    alert_type_col: str = "alert_type",
    top_n: int = 20,
) -> pd.DataFrame:
    """
    ë°°ì¹˜ë¡œ ì—¬ëŸ¬ ì„¸ê·¸ë¨¼íŠ¸ì˜ ì„¤ëª… ìƒì„±
    
    Args:
        fm: ForecastModel instance
        df: ë°ì´í„° DataFrame (segment_id, residual í¬í•¨)
        kpi: KPIëª…
        residual_col: ì”ì°¨ ì»¬ëŸ¼ëª…
        alert_type_col: ì•Œë¦¼ ìœ í˜• ì»¬ëŸ¼ëª…
        top_n: ì„¤ëª… ìƒì„±í•  ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜
    
    Returns:
        DataFrame with explanations
    """
    # ìƒìœ„/í•˜ìœ„ ì„¸ê·¸ë¨¼íŠ¸ ì„ íƒ
    sorted_df = df.sort_values(residual_col, key=abs, ascending=False).head(top_n)
    
    results = []
    
    for _, row in sorted_df.iterrows():
        segment_id = row.get("segment_id", "Unknown")
        residual_pct = row.get(residual_col, 0) * 100 if residual_col in row else 0
        alert_type = row.get(alert_type_col, "normal")
        
        try:
            row_df = pd.DataFrame([row])
            explanation = generate_segment_explanation(
                fm=fm,
                row_df=row_df[fm.feature_cols] if all(c in row_df.columns for c in fm.feature_cols) else row_df,
                kpi=kpi,
                residual_pct=residual_pct,
                alert_type=alert_type,
            )
        except Exception as e:
            explanation = f"ì„¤ëª… ìƒì„± ì‹¤íŒ¨: {e}"
        
        results.append({
            "segment_id": segment_id,
            "kpi": kpi,
            "residual_pct": residual_pct,
            "alert_type": alert_type,
            "explanation": explanation,
        })
    
    return pd.DataFrame(results)


def summarize_drivers_by_category(
    fm: ForecastModel,
    df: pd.DataFrame = None,
    top_k: int = 10,
) -> Dict[str, Dict]:
    """
    ì „ì²´ ë°ì´í„°ì—ì„œ ì¹´í…Œê³ ë¦¬ë³„ ì£¼ìš” ë“œë¼ì´ë²„ ìš”ì•½
    
    Returns:
        {
            "internal": {"ì˜ˆê¸ˆì”ì•¡ (1ê°œì›” ì „)": 15.2, ...},
            "external": {"í™˜ìœ¨ (ì „ì›”ë¹„)": 8.5, ...},
            "segment": {"ì—…ì¢…_ì¤‘ë¶„ë¥˜": 12.1, ...}
        }
    """
    # ê¸€ë¡œë²Œ í”¼ì²˜ ì¤‘ìš”ë„
    importance = global_feature_importance(fm)
    
    categories = {
        "internal": {},  # ë‚´ë¶€ KPI ê´€ë ¨
        "external": {},  # ì™¸ë¶€ ê±°ì‹œê²½ì œ
        "segment": {},   # ì„¸ê·¸ë¨¼íŠ¸ ì†ì„±
        "time": {},      # ì‹œê°„ ê´€ë ¨
    }
    
    external_keywords = ["usd", "krw", "fed", "rate", "wti", "brent", "esi", "kasi", 
                         "cpi", "ppi", "export", "import", "trade", "housing", "jeonse", "apt"]
    segment_keywords = ["ì—…ì¢…", "ì§€ì—­", "ë“±ê¸‰", "ì „ë‹´", "ì‚¬ì—…ì¥", "ì‹œë„"]
    time_keywords = ["month", "quarter", "year", "sin", "cos"]
    
    for _, row in importance.head(50).iterrows():
        feat = row["feature"]
        imp = row.get("importance_pct", row.get("importance_gain_pct", 0))
        readable = get_readable_feature_name(feat)
        
        feat_lower = feat.lower()
        
        if any(kw in feat_lower for kw in external_keywords):
            categories["external"][readable] = imp
        elif any(kw in feat for kw in segment_keywords):
            categories["segment"][readable] = imp
        elif any(kw in feat_lower for kw in time_keywords):
            categories["time"][readable] = imp
        else:
            categories["internal"][readable] = imp
    
    # ê° ì¹´í…Œê³ ë¦¬ë³„ ìƒìœ„ Nê°œë§Œ ìœ ì§€
    for cat in categories:
        sorted_items = sorted(categories[cat].items(), key=lambda x: -x[1])[:top_k]
        categories[cat] = dict(sorted_items)
    
    return categories


def generate_executive_summary_report(
    fm: ForecastModel,
    alerts_df: pd.DataFrame,
    kpi: str,
    month: pd.Timestamp,
) -> str:
    """
    ê²½ì˜ì§„ìš© í•œ í˜ì´ì§€ ìš”ì•½ ìƒì„±
    
    Args:
        fm: ForecastModel instance
        alerts_df: ê²½ë³´ DataFrame
        kpi: KPIëª…
        month: ë¶„ì„ ì›”
    
    Returns:
        ìš”ì•½ ë¬¸ìì—´
    """
    lines = [
        "=" * 60,
        f"ğŸ“Š {kpi} ì›”ê°„ ë¶„ì„ ìš”ì•½",
        f"ë¶„ì„ ê¸°ì¤€: {month.strftime('%Yë…„ %mì›”')}",
        "=" * 60,
        "",
    ]
    
    # ë“œë¼ì´ë²„ ë¶„ì„
    try:
        drivers = summarize_drivers_by_category(fm, None)
        
        if drivers.get("external"):
            lines.append("â–  ì£¼ìš” ì™¸ë¶€ ì˜í–¥ ìš”ì¸")
            for feat, imp in list(drivers["external"].items())[:3]:
                lines.append(f"  â€¢ {feat}: ì¤‘ìš”ë„ {imp:.1f}%")
            lines.append("")
        
        if drivers.get("internal"):
            lines.append("â–  ì£¼ìš” ë‚´ë¶€ ì˜í–¥ ìš”ì¸")
            for feat, imp in list(drivers["internal"].items())[:3]:
                lines.append(f"  â€¢ {feat}: ì¤‘ìš”ë„ {imp:.1f}%")
            lines.append("")
    except:
        pass
    
    # ê²½ë³´ ìš”ì•½
    if not alerts_df.empty:
        n_drop = len(alerts_df[alerts_df.get("alert_type", "") == "DROP"])
        n_surge = len(alerts_df[alerts_df.get("alert_type", "") == "SPIKE"])
        n_critical = len(alerts_df[alerts_df.get("severity", "") == "CRITICAL"])
        
        lines.append("â–  ê²½ë³´ í˜„í™©")
        lines.append(f"  â€¢ ê¸‰ê° ì„¸ê·¸ë¨¼íŠ¸: {n_drop}ê±´")
        lines.append(f"  â€¢ ê¸‰ì¦ ì„¸ê·¸ë¨¼íŠ¸: {n_surge}ê±´")
        lines.append(f"  â€¢ Critical ë“±ê¸‰: {n_critical}ê±´")
        lines.append("")
        
        # ëŒ€í‘œ ê²½ë³´ 1ê±´ ì„¤ëª…
        if n_critical > 0:
            critical = alerts_df[alerts_df.get("severity", "") == "CRITICAL"].iloc[0]
            seg_id = critical.get("segment_id", "N/A")
            lines.append(f"â–  ëŒ€í‘œ ê²½ë³´ ì„¸ê·¸ë¨¼íŠ¸: {seg_id}")
            
            if "explanation" in critical:
                lines.append(f"  {critical['explanation']}")
            lines.append("")
    
    # ê¶Œê³ ì‚¬í•­
    lines.append("â–  ê¶Œê³ ì‚¬í•­")
    lines.append("  1. ê¸‰ê° ì„¸ê·¸ë¨¼íŠ¸ì— ëŒ€í•œ ê¸´ê¸‰ RM ì»¨íƒ í•„ìš”")
    lines.append("  2. ì™¸ë¶€ ê±°ì‹œê²½ì œ ë³€ë™ì— ë”°ë¥¸ ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„°ë§ ê°•í™”")
    lines.append("  3. Critical ë“±ê¸‰ ì„¸ê·¸ë¨¼íŠ¸ ì£¼ê°„ ì¶”ì  ê´€ë¦¬")
    
    return "\n".join(lines)

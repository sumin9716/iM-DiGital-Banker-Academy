"""
Transformer ëª¨ë¸ ê°œì„ : ë°ì´í„° ì¦ê°• + í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹

ê°œì„  ì „ëµ:
1. ë°ì´í„° ì¦ê°•: Jittering, Scaling, Time Warping, Window Slicing, Mixup
2. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹: Optuna ê¸°ë°˜ ìë™ íƒìƒ‰
3. ëª¨ë¸ ê°œì„ : Pre-LayerNorm, Learnable Positional Encoding
4. ì •ê·œí™” ê°•í™”: Label Smoothing, Dropout Scheduling
"""

import argparse
import warnings
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import random

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

warnings.filterwarnings('ignore')

# ì¬í˜„ì„±
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)

# ë””ë°”ì´ìŠ¤ ì„¤ì •
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')
print(f"Using device: {DEVICE}")


# ============================================================================
# 1. ë°ì´í„° ì¦ê°• í´ë˜ìŠ¤
# ============================================================================

class TimeSeriesAugmentation:
    """ì‹œê³„ì—´ ë°ì´í„° ì¦ê°• ê¸°ë²•"""
    
    def __init__(self, 
                 jitter_sigma: float = 0.03,
                 scale_sigma: float = 0.1,
                 time_warp_sigma: float = 0.2,
                 window_slice_ratio: float = 0.9,
                 mixup_alpha: float = 0.2,
                 augment_prob: float = 0.5):
        """
        Args:
            jitter_sigma: Jittering ë…¸ì´ì¦ˆ ê°•ë„
            scale_sigma: Scaling ë³€í˜• ê°•ë„
            time_warp_sigma: Time Warping ê°•ë„
            window_slice_ratio: Window Slicing ë¹„ìœ¨
            mixup_alpha: Mixup Beta ë¶„í¬ íŒŒë¼ë¯¸í„°
            augment_prob: ê° ì¦ê°• ì ìš© í™•ë¥ 
        """
        self.jitter_sigma = jitter_sigma
        self.scale_sigma = scale_sigma
        self.time_warp_sigma = time_warp_sigma
        self.window_slice_ratio = window_slice_ratio
        self.mixup_alpha = mixup_alpha
        self.augment_prob = augment_prob
    
    def jittering(self, x: np.ndarray) -> np.ndarray:
        """ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì¶”ê°€"""
        noise = np.random.normal(0, self.jitter_sigma, x.shape)
        return x + noise
    
    def scaling(self, x: np.ndarray) -> np.ndarray:
        """ìŠ¤ì¼€ì¼ ë³€í™˜"""
        scalers = np.random.normal(1, self.scale_sigma, (1, x.shape[1]))
        return x * scalers
    
    def magnitude_warping(self, x: np.ndarray) -> np.ndarray:
        """í¬ê¸° ì™œê³¡"""
        seq_len, n_features = x.shape
        
        # ë¶€ë“œëŸ¬ìš´ ê³¡ì„  ìƒì„±
        knot = 4
        t = np.arange(seq_len)
        knot_points = np.random.normal(1, self.scale_sigma, (knot, n_features))
        
        # ì„ í˜• ë³´ê°„
        from scipy.interpolate import interp1d
        orig_steps = np.linspace(0, seq_len - 1, num=knot)
        
        warped = np.zeros_like(x)
        for i in range(n_features):
            f = interp1d(orig_steps, knot_points[:, i], kind='linear', fill_value='extrapolate')
            warped[:, i] = x[:, i] * f(t)
        
        return warped
    
    def time_warping(self, x: np.ndarray) -> np.ndarray:
        """ì‹œê°„ ì¶• ì™œê³¡"""
        from scipy.interpolate import interp1d
        
        seq_len, n_features = x.shape
        
        # ì™œê³¡ëœ ì‹œê°„ ì¶• ìƒì„±
        knot = 4
        orig_steps = np.linspace(0, seq_len - 1, num=knot)
        random_warps = np.random.normal(loc=1.0, scale=self.time_warp_sigma, size=knot)
        random_warps = np.abs(random_warps)  # ì–‘ìˆ˜ ë³´ì¥
        warp_steps = np.cumsum(random_warps)
        warp_steps = (warp_steps - warp_steps[0]) / (warp_steps[-1] - warp_steps[0]) * (seq_len - 1)
        
        # ë³´ê°„
        warped = np.zeros_like(x)
        for i in range(n_features):
            f = interp1d(warp_steps, x[np.linspace(0, seq_len-1, knot).astype(int), i], 
                        kind='linear', fill_value='extrapolate')
            warped[:, i] = f(np.arange(seq_len))
        
        return warped
    
    def window_slicing(self, x: np.ndarray) -> np.ndarray:
        """ìœˆë„ìš° ìŠ¬ë¼ì´ì‹±"""
        seq_len, n_features = x.shape
        target_len = int(seq_len * self.window_slice_ratio)
        
        if target_len < seq_len:
            start = np.random.randint(0, seq_len - target_len + 1)
            sliced = x[start:start + target_len]
            
            # ì›ë˜ ê¸¸ì´ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
            from scipy.ndimage import zoom
            scale_factor = seq_len / target_len
            resized = zoom(sliced, (scale_factor, 1), order=1)
            
            # í¬ê¸° ì¡°ì •
            if resized.shape[0] > seq_len:
                resized = resized[:seq_len]
            elif resized.shape[0] < seq_len:
                pad = np.zeros((seq_len - resized.shape[0], n_features))
                resized = np.vstack([resized, pad])
            
            return resized
        return x
    
    def permutation(self, x: np.ndarray, max_segments: int = 5) -> np.ndarray:
        """ì„¸ê·¸ë¨¼íŠ¸ ìˆœì„œ ì„ê¸°"""
        seq_len, n_features = x.shape
        n_segs = np.random.randint(2, max_segments + 1)
        
        splits = np.array_split(np.arange(seq_len), n_segs)
        random.shuffle(splits)
        
        permuted_indices = np.concatenate(splits)
        return x[permuted_indices]
    
    def crop_and_resize(self, x: np.ndarray, crop_ratio: float = 0.8) -> np.ndarray:
        """ëœë¤ í¬ë¡­ í›„ ë¦¬ì‚¬ì´ì¦ˆ"""
        from scipy.ndimage import zoom
        
        seq_len, n_features = x.shape
        crop_len = int(seq_len * crop_ratio)
        start = np.random.randint(0, seq_len - crop_len + 1)
        cropped = x[start:start + crop_len]
        
        # ì›ë˜ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        scale_factor = seq_len / crop_len
        resized = zoom(cropped, (scale_factor, 1), order=1)
        
        if resized.shape[0] > seq_len:
            resized = resized[:seq_len]
        elif resized.shape[0] < seq_len:
            pad = np.zeros((seq_len - resized.shape[0], n_features))
            resized = np.vstack([resized, pad])
        
        return resized
    
    def augment(self, x: np.ndarray, augment_type: Optional[str] = None) -> np.ndarray:
        """ì¦ê°• ì ìš©"""
        if augment_type is None:
            # ëœë¤ ì„ íƒ
            augment_types = ['jitter', 'scale', 'magnitude_warp', 'time_warp', 
                           'window_slice', 'permutation', 'crop_resize']
            augment_type = random.choice(augment_types)
        
        if random.random() > self.augment_prob:
            return x
        
        if augment_type == 'jitter':
            return self.jittering(x)
        elif augment_type == 'scale':
            return self.scaling(x)
        elif augment_type == 'magnitude_warp':
            return self.magnitude_warping(x)
        elif augment_type == 'time_warp':
            return self.time_warping(x)
        elif augment_type == 'window_slice':
            return self.window_slicing(x)
        elif augment_type == 'permutation':
            return self.permutation(x)
        elif augment_type == 'crop_resize':
            return self.crop_and_resize(x)
        else:
            return x
    
    def augment_batch(self, X: np.ndarray, n_augment: int = 2) -> Tuple[np.ndarray, np.ndarray]:
        """ë°°ì¹˜ ì¦ê°• (n_augmentë°°ë¡œ í™•ì¥)"""
        augmented_X = [X]
        
        for _ in range(n_augment):
            aug_batch = np.array([self.augment(x) for x in X])
            augmented_X.append(aug_batch)
        
        return np.concatenate(augmented_X, axis=0)


class AugmentedSequenceDataset(Dataset):
    """ì¦ê°•ì´ ì ìš©ëœ ì‹œí€€ìŠ¤ ë°ì´í„°ì…‹"""
    
    def __init__(self, samples: np.ndarray, targets: np.ndarray,
                 augment: bool = True, augmenter: Optional[TimeSeriesAugmentation] = None):
        self.samples = samples
        self.targets = targets
        self.augment = augment
        self.augmenter = augmenter or TimeSeriesAugmentation()
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        x = self.samples[idx].copy()
        y = self.targets[idx]
        
        if self.augment and self.training:
            x = self.augmenter.augment(x)
        
        return torch.FloatTensor(x), torch.FloatTensor([y])
    
    @property
    def training(self):
        return self.augment


# ============================================================================
# 2. ê°œì„ ëœ Transformer ëª¨ë¸
# ============================================================================

class LearnablePositionalEncoding(nn.Module):
    """í•™ìŠµ ê°€ëŠ¥í•œ ìœ„ì¹˜ ì¸ì½”ë”©"""
    
    def __init__(self, d_model: int, max_len: int = 100, dropout: float = 0.1):
        super().__init__()
        self.dropout = nn.Dropout(p=dropout)
        self.pe = nn.Parameter(torch.randn(1, max_len, d_model) * 0.02)
    
    def forward(self, x):
        x = x + self.pe[:, :x.size(1), :]
        return self.dropout(x)


class PreNormTransformerLayer(nn.Module):
    """Pre-LayerNorm Transformer Layer (ë” ì•ˆì •ì ì¸ í•™ìŠµ)"""
    
    def __init__(self, d_model: int, nhead: int, dim_feedforward: int, dropout: float = 0.1):
        super().__init__()
        
        self.norm1 = nn.LayerNorm(d_model)
        self.norm2 = nn.LayerNorm(d_model)
        
        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)
        
        self.ff = nn.Sequential(
            nn.Linear(d_model, dim_feedforward),
            nn.GELU(),  # ReLU ëŒ€ì‹  GELU
            nn.Dropout(dropout),
            nn.Linear(dim_feedforward, d_model),
            nn.Dropout(dropout)
        )
    
    def forward(self, x, src_mask=None):
        # Pre-Norm: Layer Norm -> Attention -> Residual
        x2 = self.norm1(x)
        x = x + self.self_attn(x2, x2, x2, attn_mask=src_mask)[0]
        
        # Pre-Norm: Layer Norm -> FFN -> Residual
        x2 = self.norm2(x)
        x = x + self.ff(x2)
        
        return x


class ImprovedTransformerModel(nn.Module):
    """ê°œì„ ëœ Transformer ëª¨ë¸"""
    
    def __init__(self, input_dim: int, d_model: int = 128, 
                 nhead: int = 8, num_layers: int = 4, 
                 dim_feedforward: int = 512, dropout: float = 0.1,
                 use_learnable_pe: bool = True):
        super().__init__()
        
        # ì…ë ¥ í”„ë¡œì ì…˜ (ìŠ¤ë¬´ìŠ¤í•œ ë³€í™˜)
        self.input_projection = nn.Sequential(
            nn.Linear(input_dim, d_model),
            nn.LayerNorm(d_model),
            nn.Dropout(dropout)
        )
        
        # ìœ„ì¹˜ ì¸ì½”ë”©
        if use_learnable_pe:
            self.pos_encoder = LearnablePositionalEncoding(d_model, dropout=dropout)
        else:
            self.pos_encoder = self._sinusoidal_pe(d_model, dropout)
        
        # Pre-Norm Transformer Layers
        self.layers = nn.ModuleList([
            PreNormTransformerLayer(d_model, nhead, dim_feedforward, dropout)
            for _ in range(num_layers)
        ])
        
        self.final_norm = nn.LayerNorm(d_model)
        
        # ì¶œë ¥ í—¤ë“œ (ë” ê¹Šì€ êµ¬ì¡°)
        self.fc = nn.Sequential(
            nn.Linear(d_model, d_model // 2),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(d_model // 2, d_model // 4),
            nn.GELU(),
            nn.Dropout(dropout / 2),  # ì ì§„ì  dropout ê°ì†Œ
            nn.Linear(d_model // 4, 1)
        )
        
        # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”
        self._init_weights()
    
    def _init_weights(self):
        """Xavier/He ì´ˆê¸°í™”"""
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
    
    def _sinusoidal_pe(self, d_model: int, dropout: float):
        """ì‚¬ì¸ ìœ„ì¹˜ ì¸ì½”ë”© (í´ë°±)"""
        from deep_learning_models import PositionalEncoding
        return PositionalEncoding(d_model, dropout=dropout)
    
    def forward(self, x, return_attention: bool = False):
        # x: (batch, seq_len, features)
        x = self.input_projection(x)
        x = self.pos_encoder(x)
        
        # Transformer layers
        for layer in self.layers:
            x = layer(x)
        
        x = self.final_norm(x)
        
        # ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í… + í‰ê·  í’€ë§ ê²°í•©
        last_out = x[:, -1, :]
        mean_out = x.mean(dim=1)
        combined = (last_out + mean_out) / 2
        
        return self.fc(combined)


# ============================================================================
# 3. í•™ìŠµ ê´€ë ¨ ìœ í‹¸ë¦¬í‹°
# ============================================================================

class SmoothL1Loss(nn.Module):
    """Smooth L1 Loss (Huber Loss) - ì´ìƒì¹˜ì— ê°•ê±´"""
    
    def __init__(self, beta: float = 1.0):
        super().__init__()
        self.beta = beta
    
    def forward(self, pred, target):
        return F.smooth_l1_loss(pred, target, beta=self.beta)


class CosineAnnealingWarmupRestarts(torch.optim.lr_scheduler._LRScheduler):
    """Warmup + Cosine Annealing with Restarts"""
    
    def __init__(self, optimizer, first_cycle_steps: int, cycle_mult: float = 1.0,
                 max_lr: float = 0.001, min_lr: float = 0.00001,
                 warmup_steps: int = 10, gamma: float = 1.0, last_epoch: int = -1):
        
        self.first_cycle_steps = first_cycle_steps
        self.cycle_mult = cycle_mult
        self.base_max_lr = max_lr
        self.max_lr = max_lr
        self.min_lr = min_lr
        self.warmup_steps = warmup_steps
        self.gamma = gamma
        
        self.cur_cycle_steps = first_cycle_steps
        self.cycle = 0
        self.step_in_cycle = last_epoch
        
        super().__init__(optimizer, last_epoch)
        
        self.init_lr()
    
    def init_lr(self):
        self.base_lrs = []
        for param_group in self.optimizer.param_groups:
            param_group['lr'] = self.min_lr
            self.base_lrs.append(self.min_lr)
    
    def get_lr(self):
        if self.step_in_cycle < self.warmup_steps:
            return [(self.max_lr - base_lr) * self.step_in_cycle / self.warmup_steps + base_lr 
                    for base_lr in self.base_lrs]
        else:
            return [base_lr + (self.max_lr - base_lr) * 
                    (1 + np.cos(np.pi * (self.step_in_cycle - self.warmup_steps) / 
                               (self.cur_cycle_steps - self.warmup_steps))) / 2
                    for base_lr in self.base_lrs]
    
    def step(self, epoch=None):
        if epoch is None:
            epoch = self.last_epoch + 1
            self.step_in_cycle = self.step_in_cycle + 1
            
            if self.step_in_cycle >= self.cur_cycle_steps:
                self.cycle += 1
                self.step_in_cycle = 0
                self.cur_cycle_steps = int(self.cur_cycle_steps * self.cycle_mult)
                self.max_lr = self.base_max_lr * (self.gamma ** self.cycle)
        else:
            self.step_in_cycle = epoch
        
        self.last_epoch = epoch
        
        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):
            param_group['lr'] = lr


def train_with_augmentation(
    model: nn.Module, 
    train_samples: np.ndarray,
    train_targets: np.ndarray,
    val_samples: np.ndarray,
    val_targets: np.ndarray,
    epochs: int = 100,
    batch_size: int = 64,
    lr: float = 0.001,
    patience: int = 15,
    use_augmentation: bool = True,
    verbose: bool = True
) -> Dict:
    """ì¦ê°•ì„ ì ìš©í•œ í•™ìŠµ"""
    
    model = model.to(DEVICE)
    
    # ì¦ê°•ê¸°
    augmenter = TimeSeriesAugmentation(
        jitter_sigma=0.03,
        scale_sigma=0.1,
        time_warp_sigma=0.2,
        augment_prob=0.5
    )
    
    # ê²€ì¦ ë°ì´í„° (ì¦ê°• ì—†ìŒ)
    val_dataset = AugmentedSequenceDataset(val_samples, val_targets, augment=False)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
    
    # Optimizer & Scheduler
    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)
    scheduler = CosineAnnealingWarmupRestarts(
        optimizer, first_cycle_steps=epochs // 3,
        max_lr=lr, min_lr=lr / 100, warmup_steps=epochs // 10
    )
    
    criterion = SmoothL1Loss(beta=1.0)
    
    best_val_loss = float('inf')
    best_model_state = None
    patience_counter = 0
    history = {'train_loss': [], 'val_loss': [], 'lr': []}
    
    for epoch in range(epochs):
        # ë§¤ ì—í­ë§ˆë‹¤ ìƒˆë¡œìš´ ì¦ê°• ì ìš©
        if use_augmentation:
            # ì›ë³¸ + ì¦ê°• ë°ì´í„°
            aug_samples = augmenter.augment_batch(train_samples, n_augment=2)
            aug_targets = np.tile(train_targets, 3)  # 3ë°°
        else:
            aug_samples = train_samples
            aug_targets = train_targets
        
        train_dataset = AugmentedSequenceDataset(aug_samples, aug_targets, augment=False)
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        
        # Training
        model.train()
        train_loss = 0.0
        for X_batch, y_batch in train_loader:
            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)
            
            optimizer.zero_grad()
            y_pred = model(X_batch)
            loss = criterion(y_pred, y_batch)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
            
            train_loss += loss.item()
        
        train_loss /= len(train_loader)
        
        # Validation
        model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for X_batch, y_batch in val_loader:
                X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)
                y_pred = model(X_batch)
                loss = criterion(y_pred, y_batch)
                val_loss += loss.item()
        
        val_loss /= len(val_loader)
        
        current_lr = optimizer.param_groups[0]['lr']
        scheduler.step()
        
        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['lr'].append(current_lr)
        
        # Early stopping
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            best_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}
            patience_counter = 0
        else:
            patience_counter += 1
        
        if verbose and (epoch + 1) % 10 == 0:
            print(f"  Epoch {epoch+1}/{epochs}: Train={train_loss:.4f}, Val={val_loss:.4f}, LR={current_lr:.6f}")
        
        if patience_counter >= patience:
            if verbose:
                print(f"  Early stopping at epoch {epoch+1}")
            break
    
    # ìµœì  ëª¨ë¸ ë³µì›
    if best_model_state:
        model.load_state_dict(best_model_state)
    
    return {'history': history, 'best_val_loss': best_val_loss}


def evaluate_model(model: nn.Module, samples: np.ndarray, targets: np.ndarray,
                  batch_size: int = 64) -> Dict:
    """ëª¨ë¸ í‰ê°€"""
    
    model.eval()
    model = model.to(DEVICE)
    
    dataset = AugmentedSequenceDataset(samples, targets, augment=False)
    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)
    
    all_preds = []
    all_targets = []
    
    with torch.no_grad():
        for X_batch, y_batch in loader:
            X_batch = X_batch.to(DEVICE)
            y_pred = model(X_batch)
            all_preds.extend(y_pred.cpu().numpy().flatten())
            all_targets.extend(y_batch.numpy().flatten())
    
    y_true = np.array(all_targets)
    y_pred = np.array(all_preds)
    
    # ë©”íŠ¸ë¦­ ê³„ì‚°
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    r2 = r2_score(y_true, y_pred)
    
    # SMAPE
    denom = (np.abs(y_true) + np.abs(y_pred)) / 2.0
    denom = np.maximum(denom, 1e-9)
    smape = np.mean(np.abs(y_true - y_pred) / denom) * 100
    
    return {'mae': mae, 'rmse': rmse, 'r2': r2, 'smape': smape}


# ============================================================================
# 4. Optuna ê¸°ë°˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
# ============================================================================

def objective(trial, train_samples, train_targets, val_samples, val_targets, input_dim):
    """Optuna ìµœì í™” ëª©ì  í•¨ìˆ˜"""
    
    # í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ ê³µê°„
    d_model = trial.suggest_categorical('d_model', [64, 128, 256])
    nhead = trial.suggest_categorical('nhead', [4, 8])
    num_layers = trial.suggest_int('num_layers', 2, 6)
    dim_feedforward = trial.suggest_categorical('dim_feedforward', [256, 512, 1024])
    dropout = trial.suggest_float('dropout', 0.05, 0.3)
    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)
    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])
    
    # d_modelì´ nheadë¡œ ë‚˜ëˆ„ì–´ ë–¨ì–´ì§€ë„ë¡ ì¡°ì •
    while d_model % nhead != 0:
        nhead = nhead // 2
    
    # ëª¨ë¸ ìƒì„±
    model = ImprovedTransformerModel(
        input_dim=input_dim,
        d_model=d_model,
        nhead=nhead,
        num_layers=num_layers,
        dim_feedforward=dim_feedforward,
        dropout=dropout
    )
    
    # í•™ìŠµ
    result = train_with_augmentation(
        model, train_samples, train_targets, val_samples, val_targets,
        epochs=50,  # íŠœë‹ ì‹œì—ëŠ” ì§§ê²Œ
        batch_size=batch_size,
        lr=lr,
        patience=10,
        use_augmentation=True,
        verbose=False
    )
    
    # í‰ê°€
    metrics = evaluate_model(model, val_samples, val_targets)
    
    return metrics['r2']  # RÂ² ìµœëŒ€í™”


def run_hyperparameter_tuning(train_samples, train_targets, val_samples, val_targets,
                             input_dim: int, n_trials: int = 30):
    """í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹¤í–‰"""
    import optuna
    
    print("\nğŸ“Š Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘...")
    print(f"   ì‹œë„ íšŸìˆ˜: {n_trials}")
    
    study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=SEED))
    
    study.optimize(
        lambda trial: objective(trial, train_samples, train_targets, 
                               val_samples, val_targets, input_dim),
        n_trials=n_trials,
        show_progress_bar=True
    )
    
    print(f"\nâœ… ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:")
    for key, value in study.best_params.items():
        print(f"   {key}: {value}")
    print(f"\n   ìµœì  RÂ²: {study.best_value:.4f}")
    
    return study.best_params, study.best_value


# ============================================================================
# 5. ë©”ì¸ í•¨ìˆ˜
# ============================================================================

def prepare_sequence_data(df: pd.DataFrame, feature_cols: List[str],
                         target_col: str, group_col: str, time_col: str,
                         seq_len: int = 6, test_ratio: float = 0.2):
    """ì‹œí€€ìŠ¤ ë°ì´í„° ì¤€ë¹„"""
    
    df = df.sort_values([group_col, time_col])
    
    # RobustScaler ì‚¬ìš© (ì´ìƒì¹˜ì— ê°•ê±´)
    scaler_X = RobustScaler()
    scaler_y = RobustScaler()
    
    X_scaled = scaler_X.fit_transform(df[feature_cols].fillna(0))
    y_scaled = scaler_y.fit_transform(df[[target_col]].fillna(0))
    
    df_scaled = df.copy()
    df_scaled[feature_cols] = X_scaled
    df_scaled[target_col] = y_scaled.flatten()
    
    # ì‹œí€€ìŠ¤ ìƒì„±
    samples = []
    targets = []
    
    for group_id, group_df in df_scaled.groupby(group_col):
        group_df = group_df.sort_values(time_col)
        X = group_df[feature_cols].values
        y = group_df[target_col].values
        
        for i in range(len(group_df) - seq_len):
            samples.append(X[i:i+seq_len])
            targets.append(y[i+seq_len])
    
    samples = np.array(samples)
    targets = np.array(targets)
    
    # ì‹œê°„ ê¸°ì¤€ ë¶„í• 
    split_idx = int(len(samples) * (1 - test_ratio))
    
    train_samples = samples[:split_idx]
    train_targets = targets[:split_idx]
    test_samples = samples[split_idx:]
    test_targets = targets[split_idx:]
    
    return train_samples, train_targets, test_samples, test_targets, scaler_X, scaler_y


def main():
    parser = argparse.ArgumentParser(description='Transformer ëª¨ë¸ ê°œì„ ')
    parser.add_argument('--raw_csv', type=str, required=True)
    parser.add_argument('--external_dir', type=str, required=True)
    parser.add_argument('--seq_len', type=int, default=6)
    parser.add_argument('--epochs', type=int, default=100)
    parser.add_argument('--batch_size', type=int, default=64)
    parser.add_argument('--n_trials', type=int, default=20, help='Optuna íŠœë‹ íšŸìˆ˜')
    parser.add_argument('--skip_tuning', action='store_true', help='íŠœë‹ ê±´ë„ˆë›°ê¸°')
    args = parser.parse_args()
    
    print("=" * 70)
    print("ğŸš€ Transformer ëª¨ë¸ ê°œì„ : ë°ì´í„° ì¦ê°• + í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹")
    print("=" * 70)
    
    # ê²½ë¡œ ì„¤ì •
    import sys
    sys.path.insert(0, str(Path(__file__).resolve().parent.parent / "src"))
    
    from imradar.data.io import load_internal_csv
    from imradar.data.preprocess import aggregate_to_segment_month, build_full_panel
    from imradar.features.kpi import compute_kpis
    from imradar.features.lags import add_lag_features
    from imradar.config import RadarConfig
    
    cfg = RadarConfig()
    KPI_COLS = list(cfg.kpi_defs.keys())
    
    # ë°ì´í„° ë¡œë“œ
    print("\n[1/6] ë°ì´í„° ë¡œë“œ...")
    raw = load_internal_csv(Path(args.raw_csv))
    print(f"  âœ“ ì›ë³¸ ë°ì´í„°: {len(raw):,}í–‰")
    
    # ì „ì²˜ë¦¬
    print("[2/6] ì „ì²˜ë¦¬...")
    agg = aggregate_to_segment_month(raw, cfg)
    panel_result = build_full_panel(agg, cfg)
    panel = panel_result.panel if hasattr(panel_result, 'panel') else panel_result
    panel = compute_kpis(panel, cfg)
    print(f"  âœ“ íŒ¨ë„ ë°ì´í„°: {len(panel):,}í–‰")
    
    # í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
    print("[3/6] í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§...")
    panel = add_lag_features(
        panel, group_col='segment_id', time_col='month',
        value_cols=[c for c in KPI_COLS if c in panel.columns]
    )
    
    exclude_cols = ['segment_id', 'month', 'segment_name'] + [c for c in panel.columns if 'target' in c]
    feature_cols = [c for c in panel.columns 
                   if panel[c].dtype in ['float64', 'float32', 'int64', 'int32']
                   and c not in exclude_cols]
    print(f"  âœ“ í”¼ì²˜: {len(feature_cols)}ê°œ")
    
    # íƒ€ê²Ÿ ì„¤ì •
    target_col = 'ìˆœìœ ì…'
    if target_col not in panel.columns:
        target_col = 'slog1p_ìˆœìœ ì…'
    
    # ì‹œí€€ìŠ¤ ë°ì´í„° ì¤€ë¹„
    print("\n[4/6] ì‹œí€€ìŠ¤ ë°ì´í„° ì¤€ë¹„...")
    train_samples, train_targets, test_samples, test_targets, scaler_X, scaler_y = \
        prepare_sequence_data(panel, feature_cols, target_col, 
                             'segment_id', 'month', seq_len=args.seq_len)
    
    print(f"  âœ“ Train: {len(train_samples):,} sequences")
    print(f"  âœ“ Test: {len(test_samples):,} sequences")
    print(f"  âœ“ Input dim: {train_samples.shape[2]}")
    
    input_dim = train_samples.shape[2]
    
    # ê²°ê³¼ ì €ì¥
    output_dir = Path(__file__).resolve().parent.parent / "outputs" / "transformer_tuning"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    results = []
    
    # ========================================================================
    # ê¸°ì¡´ Transformer (ë² ì´ìŠ¤ë¼ì¸)
    # ========================================================================
    print("\n" + "=" * 70)
    print("ğŸ“Œ 1. ê¸°ì¡´ Transformer (ë² ì´ìŠ¤ë¼ì¸)")
    print("=" * 70)
    
    baseline_model = ImprovedTransformerModel(
        input_dim=input_dim,
        d_model=128,
        nhead=8,
        num_layers=3,
        dropout=0.1
    )
    
    baseline_result = train_with_augmentation(
        baseline_model, train_samples, train_targets, test_samples, test_targets,
        epochs=args.epochs, batch_size=args.batch_size, lr=0.001,
        patience=15, use_augmentation=False, verbose=True
    )
    baseline_metrics = evaluate_model(baseline_model, test_samples, test_targets)
    
    print(f"\n  âœ… ê¸°ì¡´ Transformer ê²°ê³¼:")
    print(f"     RÂ² = {baseline_metrics['r2']:.4f}")
    print(f"     SMAPE = {baseline_metrics['smape']:.2f}%")
    
    results.append({
        'model': 'Transformer_Baseline',
        'r2': baseline_metrics['r2'],
        'smape': baseline_metrics['smape'],
        'rmse': baseline_metrics['rmse']
    })
    
    # ========================================================================
    # ë°ì´í„° ì¦ê°•ë§Œ ì ìš©
    # ========================================================================
    print("\n" + "=" * 70)
    print("ğŸ“Œ 2. ë°ì´í„° ì¦ê°• ì ìš©")
    print("=" * 70)
    
    aug_model = ImprovedTransformerModel(
        input_dim=input_dim,
        d_model=128,
        nhead=8,
        num_layers=3,
        dropout=0.1
    )
    
    aug_result = train_with_augmentation(
        aug_model, train_samples, train_targets, test_samples, test_targets,
        epochs=args.epochs, batch_size=args.batch_size, lr=0.001,
        patience=15, use_augmentation=True, verbose=True  # ì¦ê°• í™œì„±í™”
    )
    aug_metrics = evaluate_model(aug_model, test_samples, test_targets)
    
    print(f"\n  âœ… ì¦ê°• Transformer ê²°ê³¼:")
    print(f"     RÂ² = {aug_metrics['r2']:.4f}")
    print(f"     SMAPE = {aug_metrics['smape']:.2f}%")
    
    results.append({
        'model': 'Transformer_Augmented',
        'r2': aug_metrics['r2'],
        'smape': aug_metrics['smape'],
        'rmse': aug_metrics['rmse']
    })
    
    # ========================================================================
    # í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (Optuna)
    # ========================================================================
    if not args.skip_tuning:
        print("\n" + "=" * 70)
        print("ğŸ“Œ 3. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (Optuna)")
        print("=" * 70)
        
        # ê²€ì¦ìš© ë°ì´í„° ë¶„í• 
        val_split = int(len(train_samples) * 0.8)
        tune_train_samples = train_samples[:val_split]
        tune_train_targets = train_targets[:val_split]
        tune_val_samples = train_samples[val_split:]
        tune_val_targets = train_targets[val_split:]
        
        best_params, best_score = run_hyperparameter_tuning(
            tune_train_samples, tune_train_targets,
            tune_val_samples, tune_val_targets,
            input_dim=input_dim,
            n_trials=args.n_trials
        )
        
        # ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ìµœì¢… í•™ìŠµ
        print("\n[5/6] ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ìµœì¢… í•™ìŠµ...")
        
        # nhead ì¡°ì •
        nhead = best_params.get('nhead', 8)
        d_model = best_params.get('d_model', 128)
        while d_model % nhead != 0:
            nhead = nhead // 2
        
        tuned_model = ImprovedTransformerModel(
            input_dim=input_dim,
            d_model=d_model,
            nhead=nhead,
            num_layers=best_params.get('num_layers', 4),
            dim_feedforward=best_params.get('dim_feedforward', 512),
            dropout=best_params.get('dropout', 0.1)
        )
        
        tuned_result = train_with_augmentation(
            tuned_model, train_samples, train_targets, test_samples, test_targets,
            epochs=args.epochs,
            batch_size=best_params.get('batch_size', 64),
            lr=best_params.get('lr', 0.001),
            patience=20,
            use_augmentation=True,
            verbose=True
        )
        tuned_metrics = evaluate_model(tuned_model, test_samples, test_targets)
        
        print(f"\n  âœ… íŠœë‹ëœ Transformer ê²°ê³¼:")
        print(f"     RÂ² = {tuned_metrics['r2']:.4f}")
        print(f"     SMAPE = {tuned_metrics['smape']:.2f}%")
        
        results.append({
            'model': 'Transformer_Tuned',
            'r2': tuned_metrics['r2'],
            'smape': tuned_metrics['smape'],
            'rmse': tuned_metrics['rmse'],
            'params': str(best_params)
        })
        
        # ìµœì  ëª¨ë¸ ì €ì¥
        torch.save(tuned_model.state_dict(), output_dir / "transformer_tuned.pt")
    
    # ========================================================================
    # ê²°ê³¼ ë¹„êµ
    # ========================================================================
    print("\n" + "=" * 70)
    print("[6/6] ê²°ê³¼ ë¹„êµ")
    print("=" * 70)
    
    results_df = pd.DataFrame(results)
    results_df.to_csv(output_dir / "transformer_tuning_results.csv", index=False)
    
    print("\nğŸ“Š ëª¨ë¸ ë¹„êµ:")
    print("-" * 60)
    for _, row in results_df.iterrows():
        print(f"  {row['model']:25s}: RÂ²={row['r2']:7.4f}, SMAPE={row['smape']:6.2f}%")
    
    # ê°œì„ ìœ¨ ê³„ì‚°
    baseline_r2 = results_df[results_df['model'] == 'Transformer_Baseline']['r2'].values[0]
    best_row = results_df.loc[results_df['r2'].idxmax()]
    improvement = (best_row['r2'] - baseline_r2) / abs(baseline_r2) * 100
    
    print(f"\nğŸ† ìµœì  ëª¨ë¸: {best_row['model']}")
    print(f"   RÂ² ê°œì„ ìœ¨: {improvement:+.1f}%")
    
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_dir}")
    print("\nâœ… ì™„ë£Œ!")


if __name__ == "__main__":
    main()
